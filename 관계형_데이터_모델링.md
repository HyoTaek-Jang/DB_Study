### 21년 1월 18일

- 모델 : 어떤 목적을 가지고 진짜를 모방한것
- 좋은 모델 : 목적에 부합하는 모방
- 데이터 모델링의 순서

  1. 업무파악 : 업무를 먼저 얘기하면서 파악함, 기획서 작성
  2. 개념적 데이터 모델링 : 현실 업무에서 어떤 개념과 어떤 상호작용을 하는 지 심사숙고함. 여기서 ER다이어그램 등장
  3. 논리적 데이터 모델링 : 관계형 DB 패러다임에 맞는 표로서 우리의 개념을 만듬.
  4. 물리적 데이터 모델링 : 우리 데이터 베이스에 최적화 된 코드로 실제 표를 생성함.

- 데이터 모델링 : 모델을 현실로부터 뜯어내서 고도의 추상화 과정을 거쳐서 컴퓨터라는 새로운 세상에 옮겨담는것

- 말을 불신해라. 그러면 신뢰가 높아질것이다. 복명복창이 그런 예

### 개념적 데이터 모델링

- 기능 1 : 필터 기능 제공
- 기능 2 : 개념에 대해 다른 사람과 얘기할 수 있는 언어가 되줌
- 이런 기능을 제공하는 도구 ERD
  - 정보를 발견하고 표현
  - 관련된 정보를 그룹핑
  - 정보 그룹 사이의 관계를 인식
- RDB(관계형DB)는 내포관계를 허용하지 않음
- 거대 단일 테이블은 중복이 발생함.
- 테이블을 쪼개는 법을 알아야함.(상속관계 클래스 관계 같구만! )

* entity : 나중에 테이블로 만들어 질 놈. 개체를 뜻함. 그룹핑한 큰 덩어리. 폴더. 다른 폴더는 포함을 못함.
* 그루핑을 구성하는 요소 attribute. 파일 -> column
* entity들간 관계 Relation : 서로 어떤 관곈가. 쓰다. 소속 이런거 -> PK, FK가 될것임
* tuple -> row

### entity

- ui db는 서로 원인과 결과의 관계임. 사용자의 입력이 디비를 바꾸고, 디비의 데이터가 사용자 ui를 바꿈
- 서로 계속 점검해야함. 기획자랑 구현자는 db구현까지는 같이 해야함.
- 기획서에서 entity를 찾아내자! 팁 : 쓰는 화면에서 보면 entity를 찾기 쉬움.
- ER 다이어그램에서 사각형으로 표현

### attribute

- 원으로 표현
- 속성에서 식별자를 만듬. 원하는 대상을 정확히 타겟팅
- 그 대상에 대해 어떤 일을 하기 위해.
- 그 대상을 제외한 누구도 같은 값이면 안돼
- 식별자가 될 수 있는 후보키(candidate key)
- 선택된 애를 기본키 primary key 후보키 중 선택 안된 애들 대체키 alternate key -> 얘네는 성능향상을 위해 프라이머리키는 아니지만 세커너리 인덱스를 걸기 좋음
- 두 키를 합쳐서 식별할 수 있는 경우 걔네를 composite key 복합키 라고 함.
- 프라이머리 키는 밑줄을 그어줌.

### relation

- 외래키 FK 외부에서 연결된 키 PK랑 FK가 연결됨
- 관계를 삼각형으로 표현
- 복합키와 슈퍼키 차이?
- 후보키는 최소성을 만족함, 슈퍼키는 유일성은 만족하지만 최소성이 만족안함

### cardinality

- 1:1 관계 -로 표현
- 저자는 여러 댓글을 작성한다. 각 댓글은 하나의 저자만 존재한다. 1:N -<로 표현
- 각 저자는 여러 글을 작성한다. 글은 여러 저자에 의해 작성된다. N:M >-< -> 나중에 컨버팅해서 일대다로 바꿈

### optionality

- 저자는 댓글을 작성하지 않을 수도 있다. optional 저자에게 댓글은 옵션이다 O로 표현
- 각 댓글은 반드시 저자가 있다. 필수다 mandatory |로 표현

erd.yah.ac : 생코에서 만든 er다이어그램 제작 머신

### 논리적 모델링

- 개념적 모델링에서 관계형 데이터 베이스에 맞게 데이터 형식을 정리정돈함.
- Mapping Rule
  1. entity : table
  2. attribute : column
  3. relation : pk, fk
- ER Master를 쓰면 편함
- 테이블 젤 먼저 만드는건 fk가 없는 애들
- 제약조건 다는 걸 도메인을 설정한다고 함
- pk fk는 서로 종속관계를 살피면 됨. 의존하는애가 fk 혼자 있어도 되면 pk(부모)
- mapping table 결합된 관계를 나타내기 어려울때 편리함. 다대다는 보통 이렇게 사용함.

- 정제되지 않은 데이터(표)를 관계형 디비에 어울리는 표로 만들어주는 단계

- UNF 정규화가 적용되지 않은 형태의 표
- 1NF 제 1정규형 : 각 컬럼이 atomic 하다
- 제 2 정규형 : NO partial dependencies 함

### 제1 정규화

- actomic col : 각 칼럼이 값을 하나만 가져라!
- select나 order by에서 문제가 생길 수 있어서 작업을 거침
- N:M이면 새로운 테이블이 등장해야함

### 제2 정규화

- 부분 종속성으로 생긴 중복을 없앤다. 제목으로 결정되는 다른 칼럼들..
- 부분 종속성 제거

### 제3 정규화

- No transitive dependencies
- 이행적 종속성 : A-> B, B->C 와 같은 관계
- 테이블 쪼개서 해결

### 물리적 데이터 모델링

- 이상적인 표를 구체적인 제품에 맞는 현실적인 표로 만드는것
- 성능이 중요함
- 일단 해보고 성능이 어디서 저하가 발생하는지 평가를 하고 해결하는게 좋음
- slow query를 찾는 방법. ex) mysql slow query 쳐서 찾아봄
- 최후의 보루... 정규화한 구조에 손을 대는것 역정규화 denormalization
- 우선 index를 작성함. 읽기성능을 미친듯이 올리고 쓰기에서 연산이 더 걸림. 저장공간과 ㅇㅇ!
- cache를 사용하여 빠르게 처리하는것도 좋음
- 이런 과정을 거쳐도 느리면 역정규화를 사용함

### 역정규화

- 읽기기능에서 정규화때문에(join) 느려지기도 함.
- 정규화가 성능 떨어트리는게 아님.
- 그래도 해야함
- 칼럼의 역정규화 : JOIN 줄이기
- 데이블의 역정규화 : 컬럼을 기준으로 테이블을 분리
- 테이블의 역정규화 : 행을 기준으로 테이블 분리
- 관계의 역정규화 : 지름길을 만들기.
- 역정규화는 규칙이 없음. 상황마다 좋은 기술로 적용하면 돼

### 칼럼의 역정규화 : JOIN줄이기

- 어느정도 중복을 허용해주는것
- 역정규화하면 시스템의 복잡도가 높아지고 프로그램이 힘들어짐. 하지만 성능을 위해 하는 것

### 칼럼의 역정규화 - 파생 컬럼의 형성 : 계산작업을 줄이기

- SELECT author_id, COUNT(author_id) FROM topic GROUP BY author_id;
- 오쏘 아이디가 각각 몇번 나오는지 띄워줌
- 그룹 바이는 비싼 작업임
- 해결법 : 오쏘 테이블에 카운트가 늘어날때 알아서 커지게 ㅇㅇ

### 테이블의 역정규화 - 컬럼을 기준으로 테이블을 분리

- 샤딩. 성능의 한계가 있을때 여러 컴퓨터에 테이블 나눠서 쓰거나

### 테이블의 역정규화 - 행을 기준으로 테이블 분리

### 관계의 역정규화 - 지름길을 만든다.

- 다시공부
- 릴레이션 역정규화: 릴레이션의 역정규화에는 릴레이션을 병합하는 방법과 분할하는 방법이 있습니다.

- 릴레이션 병합: 두 릴레이션 간의 잦은 참조로 성능이 저하될 경우 이 문제점을 해결하기 위해 병합합니다.

- 릴레이션 분할: 릴레이션의 데이터를 검색할때는 목록중의 데이터를 순차적으로 조사하여 원하는 자료를 찾습니다. 그래서 자주 사용하지 않는 속성이나 튜플이 릴레이션에 있을 경우 검색시 성능을 저하하게 만듭니다. 이 경우에는 자주 사용하는 속성이나 튜플을 분해하여 성능을 향상시킵니다. 이 분할에는 수직 분할(자주 사용하는 속성과 그렇지 않는 속성을 구분해서 분할)과 수평 분할(자주 사용하는 튜플과 그렇지 않는 튜플을 구분해서 분할)이 있습니다.
